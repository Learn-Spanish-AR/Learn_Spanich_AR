{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow==1.0.0\n",
      "ERROR: No matching distribution found for tensorflow==1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.0.0\n",
    "#import sugartensor as tf\n",
    "#import numpy as np\n",
    "#import csv\n",
    "#import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2byte = ['<EMP>',' ', 'ṃ','-','ì','y',\"'\",'Ò',\n",
    " 'ñ',\n",
    " '·',\n",
    " 'b',\n",
    " 'q',\n",
    " 'Y',\n",
    " 'N',\n",
    " 'ê',\n",
    " '&',\n",
    " 'ồ',\n",
    " 'C',\n",
    " 'á',\n",
    " 'ú',\n",
    " 'Æ',\n",
    " '.',\n",
    " 'Ż',\n",
    " 'L',\n",
    " 'M',\n",
    " 'D',\n",
    " 'û',\n",
    " 'ó',\n",
    " 'е',\n",
    " 'Ñ',\n",
    " 'ə',\n",
    " 'ı',\n",
    " 'ř',\n",
    " 'â',\n",
    " '–',\n",
    " 'ß',\n",
    " 'ë',\n",
    " 'g',\n",
    " 'ş',\n",
    " 'Ú',\n",
    " '=',\n",
    " 'ć',\n",
    " 'e',\n",
    " 'ø',\n",
    " 'r',\n",
    " 'a',\n",
    " ':',\n",
    " 'j',\n",
    " 'Š',\n",
    " 'Ϙ',\n",
    " 'Ş',\n",
    " '?',\n",
    " 'l',\n",
    " 'S',\n",
    " '¿',\n",
    " 'à',\n",
    " 'I',\n",
    " 'B',\n",
    " 'Á',\n",
    " 'U',\n",
    " '`',\n",
    " 'H',\n",
    " 'z',\n",
    " 'n',\n",
    " 'k',\n",
    " 'ï',\n",
    " 'å',\n",
    " 'o',\n",
    " 'Ö',\n",
    " 'é',\n",
    " 'ô',\n",
    " '¨',\n",
    " 'Ō',\n",
    " 'ŏ',\n",
    " 'š',\n",
    " 'p',\n",
    " 'ń',\n",
    " 'O',\n",
    " 't',\n",
    " '→',\n",
    " '…',\n",
    " 'Ł',\n",
    " 'P',\n",
    " '‘',\n",
    " 'ý',\n",
    " 'J',\n",
    " 'Í',\n",
    " 'Q',\n",
    " 'ł',\n",
    " 'A',\n",
    " 'G',\n",
    " 'Ž',\n",
    " 'ū',\n",
    " 'Ó',\n",
    " 'm',\n",
    " 'Ш',\n",
    " 'X',\n",
    " 'F',\n",
    " '_',\n",
    " '!',\n",
    " 'f',\n",
    " 'Ð',\n",
    " ',',\n",
    " 'w',\n",
    " 'v',\n",
    " 'Î',\n",
    " 'h',\n",
    " 'í',\n",
    " 'ü',\n",
    " 'ё',\n",
    " 'i',\n",
    " 'ā',\n",
    " 'ź',\n",
    " 'æ',\n",
    " 'ð',\n",
    " '￼',\n",
    " 'Č',\n",
    " 'ō',\n",
    " 'u',\n",
    " 'ç','d','c','x','E','ã','R','K','W','毵','É','ę','Þ','ò','ő','s','T','´','Z','ª','À','ä','č','Œ','œ','V','Ä','ě','¡','ö','ė','ž']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "byte2index = {}\n",
    "for i, ch in enumerate(index2byte):\n",
    "    byte2index[ch] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "voca_size = len(index2byte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2index(str_):\n",
    "\n",
    "    # clean white space\n",
    "    str_ = ' '.join(str_.split())\n",
    "    # remove punctuation and make lower case\n",
    "    str_ = str_.translate(None, string.punctuation).lower()\n",
    "\n",
    "    res = []\n",
    "    for ch in str_:\n",
    "        try:\n",
    "            res.append(byte2index[ch])\n",
    "        except KeyError:\n",
    "            # drop OOV\n",
    "            pass\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index2str(index_list):\n",
    "    # transform label index to character\n",
    "    str_ = ''\n",
    "    for ch in index_list:\n",
    "        if ch > 0:\n",
    "            str_ += index2byte[ch]\n",
    "        elif ch == 0:  # <EOS>\n",
    "            break\n",
    "    return str_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_index(indices):\n",
    "    for index_list in indices:\n",
    "        print(index2str(index_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.sg_producer_func\n",
    "def _load_mfcc(src_list):\n",
    "\n",
    "    # label, wave_file\n",
    "    label, mfcc_file = src_list\n",
    "\n",
    "    # decode string to integer\n",
    "    label = np.frombuffer(label, np.int)\n",
    "\n",
    "    # load mfcc\n",
    "    mfcc = np.load(mfcc_file, allow_pickle=False)\n",
    "\n",
    "    # speed perturbation augmenting\n",
    "    mfcc = _augment_speech(mfcc)\n",
    "\n",
    "    return label, mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _augment_speech(mfcc):\n",
    "\n",
    "    # random frequency shift ( == speed perturbation effect on MFCC )\n",
    "    r = np.random.randint(-2, 2)\n",
    "\n",
    "    # shifting mfcc\n",
    "    mfcc = np.roll(mfcc, r, axis=0)\n",
    "\n",
    "    # zero padding\n",
    "    if r > 0:\n",
    "        mfcc[:r, :] = 0\n",
    "    elif r < 0:\n",
    "        mfcc[r:, :] = 0\n",
    "\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechCorpus(object):\n",
    "\n",
    "    def __init__(self, batch_size=16, set_name='train2'):\n",
    "\n",
    "        # load meta file\n",
    "        label, mfcc_file = [], []\n",
    "        with open('/home/kazihar/Converted0/%s.csv' % set_name) as csv_file:\n",
    "            reader = csv.reader(csv_file, delimiter='\\t')\n",
    "            for row in reader:\n",
    "                # mfcc file\n",
    "                mfcc_file.append('/home/kazihar/Converted0/' + row[0])\n",
    "                # label info ( convert to string object for variable-length support )\n",
    "                a = row[1].split(',')\n",
    "                l = []\n",
    "                for nums in a:\n",
    "                    m = \"\"\n",
    "                    for lets in nums:\n",
    "                        if lets.isdigit():\n",
    "                            m = m+lets\n",
    "                    l.append(int(m))\n",
    "                label.append(np.asarray(l, dtype=np.int).tostring())\n",
    "\n",
    "        # to constant tensor\n",
    "        label_t = tf.convert_to_tensor(label)\n",
    "        mfcc_file_t = tf.convert_to_tensor(mfcc_file)\n",
    "\n",
    "        # create queue from constant tensor\n",
    "        label_q, mfcc_file_q \\\n",
    "            = tf.train.slice_input_producer([label_t, mfcc_file_t], shuffle=True)\n",
    "\n",
    "        # create label, mfcc queue\n",
    "        label_q, mfcc_q = _load_mfcc(source=[label_q, mfcc_file_q],\n",
    "                                     dtypes=[tf.sg_intx, tf.sg_floatx],\n",
    "                                     capacity=256, num_threads=64)\n",
    "\n",
    "        # create batch queue with dynamic pad\n",
    "        batch_queue = tf.train.batch([label_q, mfcc_q], batch_size,\n",
    "                                     shapes=[(None,), (20, None)],\n",
    "                                     num_threads=64, capacity=batch_size*32,\n",
    "                                     dynamic_pad=True)\n",
    "\n",
    "        # split data\n",
    "        self.label, self.mfcc = batch_queue\n",
    "        # batch * time * dim\n",
    "        self.mfcc = self.mfcc.sg_transpose(perm=[0, 2, 1])\n",
    "        # calc total batch count\n",
    "        self.num_batch = len(label) // batch_size\n",
    "\n",
    "        # print info\n",
    "        tf.sg_info('%s set loaded.(total data=%d, total batch=%d)'\n",
    "                   % (set_name.upper(), len(label), self.num_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_blocks = 3     # dilated blocks\n",
    "num_dim = 128      # latent dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logit(x, voca_size):\n",
    "\n",
    "    # residual block\n",
    "    def res_block(tensor, size, rate, block, dim=num_dim):\n",
    "\n",
    "        with tf.sg_context(name='block_%d_%d' % (block, rate)):\n",
    "\n",
    "            # filter convolution\n",
    "            conv_filter = tensor.sg_aconv1d(size=size, rate=rate, act='tanh', bn=True, name='conv_filter')\n",
    "\n",
    "            # gate convolution\n",
    "            conv_gate = tensor.sg_aconv1d(size=size, rate=rate,  act='sigmoid', bn=True, name='conv_gate')\n",
    "\n",
    "            # output by gate multiplying\n",
    "            out = conv_filter * conv_gate\n",
    "\n",
    "            # final output\n",
    "            out = out.sg_conv1d(size=1, dim=dim, act='tanh', bn=True, name='conv_out')\n",
    "\n",
    "            # residual and skip output\n",
    "            return out + tensor, out\n",
    "\n",
    "    # expand dimension\n",
    "    with tf.sg_context(name='front'):\n",
    "        z = x.sg_conv1d(size=1, dim=num_dim, act='tanh', bn=True, name='conv_in')\n",
    "\n",
    "    # dilated conv block loop\n",
    "    skip = 0  # skip connections\n",
    "    for i in range(num_blocks):\n",
    "        for r in [1, 2, 4, 8, 16]:\n",
    "            z, s = res_block(z, size=7, rate=r, block=i)\n",
    "            skip += s\n",
    "\n",
    "    # final logit layers\n",
    "    with tf.sg_context(name='logit'):\n",
    "        logit = (skip\n",
    "                 .sg_conv1d(size=1, act='tanh', bn=True, name='conv_1')\n",
    "                 .sg_conv1d(size=1, dim=voca_size, name='conv_2'))\n",
    "\n",
    "    return logit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.sg_verbosity(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I 0610:20:12:59.954:<ipython-input-10-5c53eb943aa3>:50] TRAIN2 set loaded.(total data=89178, total batch=5573)\n"
     ]
    }
   ],
   "source": [
    "data = SpeechCorpus(batch_size=batch_size * tf.sg_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = [], []\n",
    "with open('/home/kazihar/Converted0/train1.csv') as csv_file:\n",
    "            reader = csv.reader(csv_file, delimiter='\\t')\n",
    "            for row in reader:\n",
    "                x.append(row[0])\n",
    "                y.append(str2index(row[1]))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/kazihar/Converted0/train2.csv', 'w') as csv_file:\n",
    "            writer= csv.writer(csv_file, delimiter='\\t')\n",
    "            for i in range(len(x)):\n",
    "                writer.writerow([x[i], y[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.split(data.mfcc, tf.sg_gpus(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tf.split(data.label, tf.sg_gpus(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = []\n",
    "for input_ in inputs:\n",
    "    seq_len.append(tf.not_equal(input_.sg_sum(axis=2), 0.).sg_int().sg_sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.sg_parallel\n",
    "def get_loss(opt):\n",
    "    # encode audio feature\n",
    "    logit = get_logit(opt.input[opt.gpu_index], voca_size=voca_size)\n",
    "    # CTC loss\n",
    "    return logit.sg_ctc(target=opt.target[opt.gpu_index], seq_len=opt.seq_len[opt.gpu_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I 0610:20:13:20.141:sg_train.py:327] Training started from epoch[000]-step[0].\n",
      "train:   0%|                       | 2/5573 [00:53<39:12:59, 25.34s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.0334968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   0%|                       | 4/5573 [01:41<36:26:53, 23.56s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.0333329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   0%|                       | 7/5573 [02:50<35:30:44, 22.97s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.0500006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   0%|                       | 9/5573 [03:44<39:03:07, 25.27s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.0333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   0%|                      | 12/5573 [04:53<36:54:41, 23.90s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.0500001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   0%|                      | 15/5573 [05:55<32:13:05, 20.87s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   0%|                      | 17/5573 [06:43<33:54:00, 21.97s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.0333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   0%|                      | 21/5573 [07:56<27:46:39, 18.01s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.0666668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   0%|                      | 23/5573 [08:52<34:24:24, 22.32s/b]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.0333327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   1%|▏                     | 62/5573 [23:59<33:33:12, 21.92s/b]"
     ]
    }
   ],
   "source": [
    "tf.sg_train(lr=0.0001, loss=get_loss(input=inputs, target=labels, seq_len=seq_len),\n",
    "            ep_size=data.num_batch, max_ep=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Recognise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support pip 21.0 will remove support for this functionality.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Processing /home/kazihar/.cache/pip/wheels/6a/ae/a3/9926619fb71320153272a879bcae86f4b1e813b5da5e482a80/librosa-0.7.2-py2-none-any.whl\n",
      "Collecting numpy>=1.15.0\n",
      "  Downloading numpy-1.16.6-cp27-cp27mu-manylinux1_x86_64.whl (17.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.0 MB 649 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn!=0.19.0,>=0.14.0\n",
      "  Using cached scikit_learn-0.20.4-cp27-cp27mu-manylinux1_x86_64.whl (5.5 MB)\n",
      "Collecting soundfile>=0.9.0\n",
      "  Using cached SoundFile-0.10.3.post1-py2.py3-none-any.whl (21 kB)\n",
      "Collecting decorator>=3.0.0\n",
      "  Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Processing /home/kazihar/.cache/pip/wheels/fd/b3/9d/2a68163f1c28a0f2d7981a5505e301917559c68b10468bef88/audioread-2.1.9-py2-none-any.whl\n",
      "Collecting joblib>=0.12\n",
      "  Using cached joblib-0.14.1-py2.py3-none-any.whl (294 kB)\n",
      "Collecting six>=1.3\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting numba>=0.43.0\n",
      "  Using cached numba-0.47.0-cp27-cp27mu-manylinux1_x86_64.whl (3.6 MB)\n",
      "Collecting scipy>=1.0.0\n",
      "  Using cached scipy-1.2.3-cp27-cp27mu-manylinux1_x86_64.whl (24.8 MB)\n",
      "Processing /home/kazihar/.cache/pip/wheels/19/90/bb/f45e7cc1cfc8f5299c12511fccefcca90c801de995a4e7eb00/resampy-0.2.2-py2-none-any.whl\n",
      "Collecting cffi>=1.0\n",
      "  Using cached cffi-1.14.5-cp27-cp27mu-manylinux1_x86_64.whl (389 kB)\n",
      "Collecting singledispatch; python_version < \"3.4\"\n",
      "  Using cached singledispatch-3.6.2-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting llvmlite>=0.31.0dev0\n",
      "  Using cached llvmlite-0.32.1.tar.gz (104 kB)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-44.1.1-py2.py3-none-any.whl (583 kB)\n",
      "\u001b[K     |████████████████████████████████| 583 kB 284 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting funcsigs; python_version < \"3.3\"\n",
      "  Using cached funcsigs-1.0.2-py2.py3-none-any.whl (17 kB)\n",
      "Collecting enum34; python_version < \"3.4\"\n",
      "  Using cached enum34-1.1.10-py2-none-any.whl (11 kB)\n",
      "Collecting pycparser\n",
      "  Using cached pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Building wheels for collected packages: llvmlite\n",
      "  Building wheel for llvmlite (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /usr/bin/python2.7 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-utAJoE/llvmlite/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-utAJoE/llvmlite/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-L3DvT7\n",
      "       cwd: /tmp/pip-install-utAJoE/llvmlite/\n",
      "  Complete output (7 lines):\n",
      "  running bdist_wheel\n",
      "  /usr/bin/python2.7 /tmp/pip-install-utAJoE/llvmlite/ffi/build.py\n",
      "    File \"/tmp/pip-install-utAJoE/llvmlite/ffi/build.py\", line 122\n",
      "      raise ValueError(msg.format(_ver_check_skip)) from e\n",
      "                                                       ^\n",
      "  SyntaxError: invalid syntax\n",
      "  error: command '/usr/bin/python2.7' failed with exit status 1\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for llvmlite\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for llvmlite\n",
      "Failed to build llvmlite\n",
      "Installing collected packages: numpy, scipy, scikit-learn, pycparser, cffi, soundfile, decorator, audioread, joblib, six, singledispatch, llvmlite, setuptools, funcsigs, enum34, numba, resampy, librosa\n",
      "    Running setup.py install for llvmlite ... \u001b[?25lerror\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /usr/bin/python2.7 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-utAJoE/llvmlite/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-utAJoE/llvmlite/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-8Sh2Tg/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/kazihar/.local/include/python2.7/llvmlite\n",
      "         cwd: /tmp/pip-install-utAJoE/llvmlite/\n",
      "    Complete output (10 lines):\n",
      "    running install\n",
      "    running build\n",
      "    got version from file /tmp/pip-install-utAJoE/llvmlite/llvmlite/_version.py {'version': '0.32.1', 'full': 'aa11b129c0b55973067422397821ae6d44fa5e70'}\n",
      "    running build_ext\n",
      "    /usr/bin/python2.7 /tmp/pip-install-utAJoE/llvmlite/ffi/build.py\n",
      "      File \"/tmp/pip-install-utAJoE/llvmlite/ffi/build.py\", line 122\n",
      "        raise ValueError(msg.format(_ver_check_skip)) from e\n",
      "                                                         ^\n",
      "    SyntaxError: invalid syntax\n",
      "    error: command '/usr/bin/python2.7' failed with exit status 1\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python2.7 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-utAJoE/llvmlite/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-utAJoE/llvmlite/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-8Sh2Tg/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/kazihar/.local/include/python2.7/llvmlite Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install --ignore-installed librosa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.sg_verbosity(10)\n",
    "\n",
    "#\n",
    "# hyper parameters\n",
    "#\n",
    "\n",
    "batch_size = 1     # batch size\n",
    "\n",
    "#\n",
    "# inputs\n",
    "#\n",
    "\n",
    "# vocabulary size\n",
    "voca_size = data.voca_size\n",
    "\n",
    "# mfcc feature of audio\n",
    "x = tf.placeholder(dtype=tf.sg_floatx, shape=(batch_size, None, 20))\n",
    "\n",
    "# sequence length except zero-padding\n",
    "seq_len = tf.not_equal(x.sg_sum(axis=2), 0.).sg_int().sg_sum(axis=1)\n",
    "\n",
    "# encode audio feature\n",
    "logit = get_logit(x, voca_size=voca_size)\n",
    "\n",
    "# ctc decoding\n",
    "decoded, _ = tf.nn.ctc_beam_search_decoder(logit.sg_transpose(perm=[1, 0, 2]), seq_len, merge_repeated=False)\n",
    "\n",
    "# to dense tensor\n",
    "y = tf.sparse_to_dense(decoded[0].indices, decoded[0].dense_shape, decoded[0].values) + 1\n",
    "\n",
    "#\n",
    "# regcognize wave file\n",
    "#\n",
    "\n",
    "# command line argument for input wave file path\n",
    "tf.sg_arg_def(file=('', 'speech wave file to recognize.'))\n",
    "\n",
    "# load wave file\n",
    "wav, _ = librosa.load(tf.sg_arg().file, mono=True, sr=16000)\n",
    "# get mfcc feature\n",
    "mfcc = np.transpose(np.expand_dims(librosa.feature.mfcc(wav, 16000), axis=0), [0, 2, 1])\n",
    "\n",
    "# run network\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # init variables\n",
    "    tf.sg_init(sess)\n",
    "\n",
    "    # restore parameters\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('asset/train'))\n",
    "    # run session\n",
    "    label = sess.run(y, feed_dict={x: mfcc})\n",
    "\n",
    "    # print label\n",
    "    data.print_index(label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
